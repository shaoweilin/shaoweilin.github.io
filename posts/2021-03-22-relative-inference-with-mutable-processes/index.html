
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta property="og:title" content="Relative inference with mutable processes" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://shaoweilin.github.io/posts/2021-03-22-relative-inference-with-mutable-processes/" />
  
<meta property="og:description" content="We introduce a information-theoretic objective, which is a form of relative information between a discriminative model and a generative model, for learning processes using models with mutable varia..." />
  
<meta property="og:image" content="https://shaoweilin.github.io/_static/profile.jpg" />
  
<meta property="og:image:alt" content="Relative inference with mutable processes" />
  
    <title>Relative inference with mutable processes &#8212; Types from Spikes  documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about/" />
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" /> 
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="None"> 
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../blog/atom.xml"
  title="Types from Spikes"
/>
 
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../">
  
  
  
  
  
    <p class="title logo__title">Types from Spikes  documentation</p>
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../about/">
  About
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../blog/">
  Blog
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <form class="bd-search d-flex align-items-center" action="../../search/" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this site..." aria-label="Search this site..." autocomplete="off" >
</form>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/shaoweilin/" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items">  
<h2>
   <i class="fa fa-calendar"></i>
  22 March 2021 
</h2>

<ul>
        
</ul>

<h3>
  <a href="../../blog/">Recent Posts</a>
</h3>
<ul>
   
  <li>
    <a href="../2022-05-28-likelihood-greed-and-temperature-in-sequence-learning/"
      >28 May - Likelihood, greed and temperature in sequence learning</a
    >
  </li>
  
  <li>
    <a href="../2022-05-08-parametric-typeclasses-aid-generalization-in-program-synthesis/"
      >22 January - Parametric typeclasses aid generalization in program synthesis</a
    >
  </li>
  
  <li>
    <a href="../2022-01-22-information-topos-theory-motivation/"
      >22 January - Information topos theory - motivation</a
    >
  </li>
  
  <li>
    <a href="../2021-09-09-all-you-need-is-relative-information/"
      >09 September - All you need is relative information</a
    >
  </li>
  
  <li>
    <a href="../2021-06-05-spiking-neural-networks/"
      >05 June - Spiking neural networks</a
    >
  </li>
  
</ul>

<h3>
  <a href="../../blog/archive/">Archives</a>
</h3>
<ul>
   
  <li>
    <a href="../../blog/2022/">2022 (3)</a>
  </li>
    
  <li>
    <a href="../../blog/2021/">2021 (8)</a>
  </li>
    
  <li>
    <a href="../../blog/2020/">2020 (12)</a>
  </li>
    
  <li>
    <a href="../../blog/2018/">2018 (1)</a>
  </li>
    
  <li>
    <a href="../../blog/2017/">2017 (1)</a>
  </li>
    
  <li>
    <a href="../../blog/2016/">2016 (3)</a>
  </li>
    
  <li>
    <a href="../../blog/2014/">2014 (2)</a>
  </li>
    
  <li>
    <a href="../../blog/2012/">2012 (1)</a>
  </li>
   
</ul>

  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-a-mutable-process">
   What is a mutable process?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-do-we-perform-relative-inference-with-mutable-processes">
   How do we perform relative inference with mutable processes?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#is-relative-inference-necessarily-passive">
   Is relative inference necessarily passive?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-do-we-perform-online-learning-with-mutable-processes">
   How do we perform online learning with mutable processes?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-do-we-perform-relative-inference-with-limited-memory">
   How do we perform relative inference with limited memory?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-do-we-perform-relative-inference-with-limited-sensing">
   How do we perform relative inference with limited sensing?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#remark-cost-of-limited-sensing">
   Remark: Cost of limited sensing
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              

              <article class="bd-article" role="main">
                 <div class="tex2jax_ignore mathjax_ignore section" id="relative-inference-with-mutable-processes">
<h1>Relative inference with mutable processes<a class="headerlink" href="#relative-inference-with-mutable-processes" title="Permalink to this headline">#</a></h1>
<p>We introduce a information-theoretic objective, which is a form of relative information between a discriminative model and a generative model, for learning processes using models with <span class="xref myst">mutable</span> variables. This technique is known as <span class="xref myst">relative inference</span> (also called approximate inference, variational inference or variational Bayes). Such a technique is useful, for instance, for learning processes that contain latent variables.</p>
<p>We discuss natural constraints on the discriminative and generative models, and the consequences of these constraints on:</p>
<ul class="simple">
<li><p>passive/active learning;</p></li>
<li><p>online/offline learning;</p></li>
<li><p>learning with limited/unlimited memory;</p></li>
<li><p>learning with limited/unlimited sensing.</p></li>
</ul>
<p>This post is a continuation from our <a class="reference internal" href="../2020-08-28-motivic-information-path-integrals-and-spiking-networks/"><span class="doc std std-doc">series</span></a> on spiking networks, path integrals and motivic information.</p>
<div class="section" id="what-is-a-mutable-process">
<h2>What is a mutable process?<a class="headerlink" href="#what-is-a-mutable-process" title="Permalink to this headline">#</a></h2>
<p>Suppose we have a random variable <span class="math notranslate nohighlight">\(X\)</span> which represents the state of reality, the environment or the universe. This random variable may have components which are observed (data is given) or observable (data can be obtained if we want it), and it may also have components which are latent or hidden. Let the true distribution of <span class="math notranslate nohighlight">\(X\)</span> be <span class="math notranslate nohighlight">\(Q_*(X),\)</span> which may be partially unknown or fully unknown. For now, we assume that we are passive observers incapable of changing this distribution.</p>
<p>Suppose that we have a generative model <span class="math notranslate nohighlight">\(\{P(Z,X)\}\)</span> where <span class="math notranslate nohighlight">\(Z\)</span> is an auxiliary variable introduced to increase the model’s ability to approximate the true distribution. More precisely, we want to find a distribution <span class="math notranslate nohighlight">\(P(Z,X)\)</span> in the model such that the marginal <span class="math notranslate nohighlight">\(P(X)\)</span> is as close to the true distribution <span class="math notranslate nohighlight">\(Q_*(X)\)</span> as possible. Here, we may assume that closeness is measured by relative information.</p>
<p>The auxiliary variable or memory <span class="math notranslate nohighlight">\(Z\)</span> need not reflect actual latent variables in the enviroment <span class="math notranslate nohighlight">\(X.\)</span> We are not looking for guarantees that the learning algorithm will infer the true hidden states of <span class="math notranslate nohighlight">\(X\)</span>. Our only goal is to approximate the true distribution.</p>
<p>To solve this problem, we will introduce a discriminative model with mutable variables. In a model <span class="math notranslate nohighlight">\(\{Q\}\)</span>, a variable <span class="math notranslate nohighlight">\(Z\)</span> is <em>mutable</em> given <span class="math notranslate nohighlight">\(X\)</span> if the conditional distribution <span class="math notranslate nohighlight">\(Q(Z \vert X)\)</span> is known in the model and if there exists at least two distributions where <span class="math notranslate nohighlight">\(Q(Z \vert X)\)</span> is different. The first condition involves knowability, the second condition involves changeability; together, they describe controllability.</p>
<p>If we also assume that in the model, all marginals <span class="math notranslate nohighlight">\(Q(X)\)</span> are equal to the true distribution <span class="math notranslate nohighlight">\(Q_*(X),\)</span> then it follows that the joint distribution <span class="math notranslate nohighlight">\(Q(Z,X)\)</span> factors as</p>
<div class="math notranslate nohighlight">
\[
Q(Z,X) = Q(Z\vert X)Q_*(X).
\]</div>
<p>Intuitively, the model <span class="math notranslate nohighlight">\(\{Q\}\)</span> represents a class of stochastic algorithms <span class="math notranslate nohighlight">\(Q\)</span> which takes an input <span class="math notranslate nohighlight">\(X\)</span> and uses the information to update the auxiliary memory variable <span class="math notranslate nohighlight">\(Z\)</span> in a stochastically predictable way. We say that the model is <em>mutable.</em></p>
<p>A model for a process <span class="math notranslate nohighlight">\(\{Y_t\}\)</span> is <em>mutable</em> if we can find subprocesses <span class="math notranslate nohighlight">\(\{Z_t\}, \{X_t\}\)</span> such that <span class="math notranslate nohighlight">\(\{Z_t\}\)</span> is mutable given <span class="math notranslate nohighlight">\(\{X_t\}.\)</span> When the model is clear from the context, we abuse notation and say that the process itself is mutable.</p>
<p>We will show in this post that we can train generative models <span class="math notranslate nohighlight">\(\{P(Z,X)\}\)</span> using mutable processes <span class="math notranslate nohighlight">\(\{Q(Z,X)\}\)</span> and relative inference.</p>
</div>
<div class="section" id="how-do-we-perform-relative-inference-with-mutable-processes">
<h2>How do we perform relative inference with mutable processes?<a class="headerlink" href="#how-do-we-perform-relative-inference-with-mutable-processes" title="Permalink to this headline">#</a></h2>
<p>Suppose that we have two processes – the environment <span class="math notranslate nohighlight">\(X_t \in \mathcal{X},\)</span> and the memory <span class="math notranslate nohighlight">\(Z_t \in \mathcal{Z}\)</span>. Let <span class="math notranslate nohighlight">\(Q_*(X_{0\ldots T})\)</span> be the true distribution of <span class="math notranslate nohighlight">\(X_{0\ldots T}\)</span>. Suppose that we have a generative model <span class="math notranslate nohighlight">\(\{P(Z,X)\}.\)</span> Recall that our goal is to find a distribution in the model that minimizes the relative information</p>
<div class="math notranslate nohighlight">
\[\displaystyle I_{Q_*\Vert P}(X_{0\ldots T})\]</div>
<p>(or equivalently the relative information rate if we assume strong stationarity.)</p>
<p><a class="reference internal" href="../2020-10-23-machine-learning-with-relative-information/"><span class="doc std std-doc">Previously</span></a>, we discussed how this optimization problem over the space of distributions on <span class="math notranslate nohighlight">\(X\)</span> may be lifted to an optimization problem over the space of distributions on <span class="math notranslate nohighlight">\((Z,X)\)</span> using <span class="xref myst">relative inference</span>. For processes, this involves lifting the environment <span class="math notranslate nohighlight">\(X_{0\ldots T}\)</span> to a mutable process <span class="math notranslate nohighlight">\((Z_{0\ldots T}, X_{0\ldots T}).\)</span></p>
<p>Specifically, we will be considering different models <span class="math notranslate nohighlight">\(\Delta\)</span> of discriminative distributions</p>
<div class="math notranslate nohighlight">
\[Q(Z_{0\ldots T},X_{0\ldots T}) = Q_*(X_{0\ldots T}) Q(Z_{0\ldots T}\vert X_{0\ldots T})\]</div>
<p>and attempt to minimize the joint relative information</p>
<div class="math notranslate nohighlight">
\[I_{Q\Vert P}(Z_{0\ldots T},X_{0\ldots T})\]</div>
<p>as <span class="math notranslate nohighlight">\(Q\)</span> varies over the space <span class="math notranslate nohighlight">\(\Delta.\)</span> We will focus on design considerations for the different computational constraints on <span class="math notranslate nohighlight">\(\Delta.\)</span></p>
</div>
<div class="section" id="is-relative-inference-necessarily-passive">
<h2>Is relative inference necessarily passive?<a class="headerlink" href="#is-relative-inference-necessarily-passive" title="Permalink to this headline">#</a></h2>
<p>The form of relative inference we are considering here is passive by assumption. The true distribution <span class="math notranslate nohighlight">\(Q_*(X_{0\ldots T})\)</span> is unchangeable, so the states of the memory variables <span class="math notranslate nohighlight">\(Z_{0\ldots T}\)</span> have no effect on the environment <span class="math notranslate nohighlight">\(X_{0\ldots T}.\)</span></p>
<p>Conceivably, we can design relative inference methods where the memory states have an effect on the enviroment, such as in active learning, reinforcement learning or partially-ordered Markov decision processes. The memory states could cause a learning agent to act on the environment and change the distribution of <span class="math notranslate nohighlight">\(X_{0\ldots T}.\)</span> Unfortunately, we will not be considering this active form of relative inference here. A complete understanding of biological intelligence must however analyze the active case.</p>
<p>In our passive form of relative inference, the most general case for the space of joint path distributions <span class="math notranslate nohighlight">\(Q(Z_{0\ldots T}, X_{0\ldots T})\)</span> is the unconstrained space <span class="math notranslate nohighlight">\(\Delta\)</span> where <span class="math notranslate nohighlight">\(Q\)</span> factors as</p>
<div class="math notranslate nohighlight">
\[Q(Z_{0\ldots T}, X_{0\ldots T}) = Q_*(X_{0\ldots T}) Q(Z_{0\ldots T}\vert X_{0\ldots T}).\]</div>
<p>The factor <span class="math notranslate nohighlight">\(Q(Z_{0\ldots T}\vert X_{0\ldots T})\)</span> is a parameter in the optimization of <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T},X_{0\ldots T}).\)</span> It is a discriminative model for approximately inferring <span class="math notranslate nohighlight">\(Z\)</span> from <span class="math notranslate nohighlight">\(X,\)</span> as opposed to the generative model <span class="math notranslate nohighlight">\(P(Z,X)\)</span> for approximately sampling from <span class="math notranslate nohighlight">\(Q_*(X).\)</span> Relative inference involves optimization over the space of discriminative models <span class="math notranslate nohighlight">\(Q(Z,X)\)</span> and generative models <span class="math notranslate nohighlight">\(P(Z,X).\)</span></p>
<p>By the chain rule of relative information,</p>
<div class="math notranslate nohighlight">
\[I_{Q\Vert P}(Z_{0\ldots T},X_{0\ldots T}) = I_{Q\Vert P}(Z_{0\ldots T}\vert  X_{0\ldots T}) + I_{Q_*\Vert P}(X_{0\ldots T})\]</div>
<p>so a minimum value for <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T},X_{0\ldots T})\)</span> will be a lower bound for the minimum value for <span class="math notranslate nohighlight">\(I_{Q_*\Vert P}(X_{0\ldots T}).\)</span> As shown <a class="reference internal" href="../2020-10-23-machine-learning-with-relative-information/"><span class="doc std std-doc">previously</span></a>, when minimizing with <span class="math notranslate nohighlight">\(Q\)</span> varying over the unconstrained space <span class="math notranslate nohighlight">\(\Delta\)</span>, the gap <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T}\vert X_{0\ldots T})\)</span> in the bound vanishes.</p>
</div>
<div class="section" id="how-do-we-perform-online-learning-with-mutable-processes">
<h2>How do we perform online learning with mutable processes?<a class="headerlink" href="#how-do-we-perform-online-learning-with-mutable-processes" title="Permalink to this headline">#</a></h2>
<p>In the training of hidden Markov models, the Baum-Welch algorithm or forward-backward algorithm is often used. It requires knowledge of the enviroment from the start to the end of the time interval. An algorithm that only uses data from the environment from the start to the present is called an <em>online</em> learning algorithm. Otherwise, the learning algorithm is said to be <em>offline</em>.</p>
<p>To understand the difference between online learning and offline learning in relative inference, let us consider a joint distribution</p>
<div class="math notranslate nohighlight">
\[Q(Z_{0\ldots T}, X_{0\ldots T}) = Q_*(X_{0\ldots T}) Q(Z_{0\ldots T}\vert X_{0\ldots T})\]</div>
<p>in the unconstrained space <span class="math notranslate nohighlight">\(\Delta.\)</span> In the discrete time case, we may decompose the discriminative model <span class="math notranslate nohighlight">\(Q(Z_{0\ldots T}\vert X_{0\ldots T})\)</span> as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl} Q(Z_{0\ldots T}\vert X_{0\ldots T}) &amp; =  Q(Z_0 \vert X_{0\ldots T}) \\ &amp; \\ &amp; \quad  Q(Z_1 \vert Z_0,X_{0\ldots T}) \cdots \\ &amp; \\ &amp; \quad Q(Z_T \vert Z_{0\ldots (T-1)}, X_{0\ldots T}). \end{array}\end{split}\]</div>
<p>Each of the factors in the decomposition are unconstrained, so inference for each variable <span class="math notranslate nohighlight">\(Z_t\)</span> could depend on the entire environmental data <span class="math notranslate nohighlight">\(X_{0\ldots T}.\)</span> Therefore, optimizing over the unconstrained space <span class="math notranslate nohighlight">\(\Delta\)</span> corresponds to a form of offline learning where the information gap <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T}\vert X_{0\ldots T})\)</span> vanishes.</p>
<p>For computational reasons, we may require that the discriminative model performs inference on <span class="math notranslate nohighlight">\(Z_t\)</span> using only environmental data <span class="math notranslate nohighlight">\(X_{0\ldots (t-1)}\)</span> from the past. We shall assume that <span class="math notranslate nohighlight">\(Q(Z_{0\ldots T}\vert X_{0\ldots T})\)</span> has a factorization</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl} Q(Z_{0\ldots T}\vert X_{0\ldots T}) &amp; = Q(Z_0) \\ &amp; \\ &amp; \quad Q(Z_1 \vert Z_0,X_0) \cdots \\ &amp; \\ &amp; \quad Q(Z_T \vert Z_{0\ldots (T-1)}, X_{0\ldots (T-1)}) \end{array}\end{split}\]</div>
<p>and let <span class="math notranslate nohighlight">\(\Delta_\mathcal{C} \subset \Delta\)</span> be the subspace of distributions <span class="math notranslate nohighlight">\(Q(Z_{0\ldots T}, X_{0\ldots T})\)</span> with this property.  Here, the subscript <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> denotes that we have causal constraints on the distributions.</p>
<p>We may think of these factors as functionals (because they are functions of paths) parametrizing the space <span class="math notranslate nohighlight">\(\Delta_\mathcal{C}\)</span> of distributions.</p>
<p>In continuous time, the above decomposition of <span class="math notranslate nohighlight">\(Q \in \Delta_\mathcal{C}\)</span> can be written in terms of exponentials of integrals of transition rates, giving us some system of Kolmogorov equations.</p>
<p>From this factorization, we can deduce by marginalization that for all <span class="math notranslate nohighlight">\(t\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl} Q(Z_{0\ldots t}, X_{0\ldots t}) &amp; = Q(X_{0\ldots t}) Q(Z_0) \\ &amp; \\ &amp; \quad Q(Z_1 \vert Z_0,X_0) \cdots \\ &amp; \\ &amp; \quad Q(Z_t \vert Z_{0\ldots (t-1)}, X_{0\ldots (t-1)}) \end{array}\end{split}\]</div>
<p>and consequently,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl}  Q(Z_{t+1}, X_{t+1} \vert Z_{0\ldots t}, X_{0\ldots t}) &amp; = \displaystyle \frac{ Q(Z_{0\ldots (t+1)}, X_{0\ldots (t+1)}) }{ Q(Z_{0\ldots t}, X_{0\ldots t}) } \\ &amp; \\ &amp; = Q( X_{t+1} \vert X_{0\ldots t}) Q(Z_{t+1} \vert Z_{0\ldots t}, X_{0\ldots t}).\end{array}\end{split}\]</div>
<p>This implies that <span class="math notranslate nohighlight">\(Z_t\)</span> and <span class="math notranslate nohighlight">\(X_t\)</span> are <em>conditionally independent given their past</em>. In discrete-time, we define this to mean that</p>
<div class="math notranslate nohighlight">
\[Q(Z_{t+1}, X_{t+1} \vert Z_{0\ldots t}, X_{0\ldots t}) =  Q(Z_{t+1} \vert Z_{0\ldots t}, X_{0\ldots t}) Q(X_{t+1} \vert Z_{0\ldots t}, X_{0\ldots t})\]</div>
<p>and vice versa. In continuous time, the analogous definition is</p>
<div class="math notranslate nohighlight">
\[Q(Z_{t\ldots t+\delta}, X_{t\ldots t+\delta} \vert Z_{0\ldots t}, X_{0\ldots t}) \rightarrow Q(Z_{t\ldots t+\delta} \vert Z_{0\ldots t}, X_{0\ldots t}) Q(X_{t\ldots t+\delta} \vert Z_{0\ldots t}, X_{0\ldots t})\]</div>
<p>as <span class="math notranslate nohighlight">\(\delta \rightarrow 0\)</span> from above.</p>
<p>Another way to state this requirement is to say that <span class="math notranslate nohighlight">\(Z_t\)</span> does not lie in the causal cone of <span class="math notranslate nohighlight">\(X_t\)</span> and vice versa. There are interesting connections to <a class="reference external" href="https://en.wikipedia.org/wiki/Causality_conditions">causal conditions</a> (classification of space-time manifolds), <a class="reference external" href="https://en.wikipedia.org/wiki/Causal_structure">causal structures</a> (relationships between points on a continuous space) and <a class="reference external" href="https://en.wikipedia.org/wiki/Causal_sets">causal sets</a> (relationships between points on a discrete space) but we will not be exploring them in this post.</p>
<p>If <span class="math notranslate nohighlight">\(Z_t\)</span> and <span class="math notranslate nohighlight">\(X_t\)</span> are conditionally independent given their past for both <span class="math notranslate nohighlight">\(Q(Z,X)\)</span> and <span class="math notranslate nohighlight">\(P(Z,X)\)</span>, then in discrete time, the chain rule for relative information simplifies to</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl} &amp;I_{Q\Vert P}(Z_{n+1}, X_{n+1} \vert Z_{0\ldots n},X_{0\ldots n}) \\ &amp; \\ &amp;= I_{Q\Vert P}(Z_{n+1} \vert Z_{0\ldots n},X_{0\ldots n}) + I_{Q\Vert P}(X_{n+1} \vert Z_{0\ldots n},X_{0\ldots n}). \end{array}\end{split}\]</div>
<p>This chain rule has the continuous-time analogue</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl} &amp; \displaystyle \frac{d}{ds}I_{Q \Vert P} (Z_{0\ldots s}, X_{0\ldots s}) \\ &amp; \\ &amp;= \displaystyle\frac{d Z_{0\ldots s}}{ds} * \frac{\partial}{\partial Z_{0\ldots s}} I_{Q \Vert P} (Z_{0\ldots s}, X_{0\ldots s}) \\ &amp; \\ &amp;\quad +\displaystyle \frac{d X_{0\ldots s}}{ds} * \frac{\partial}{\partial X_{0\ldots s}} I_{Q \Vert P} (Z_{0\ldots s}, X_{0\ldots s})\end{array}\end{split}\]</div>
<p>which mirrors the multivariate chain rule in calculus</p>
<div class="math notranslate nohighlight">
\[\displaystyle \frac{d}{ds}f(z(s),x(s)) =\frac{dz}{ds} \frac{\partial}{\partial z} f(z,x) +\displaystyle \frac{dx}{ds} \frac{\partial}{\partial x} f(z,x).\]</div>
<p>Online learning involves minimizing over the subspace <span class="math notranslate nohighlight">\(\Delta_\mathcal{C},\)</span> where the discriminative factors <span class="math notranslate nohighlight">\(Q(Z_t \vert Z_{0\ldots (t-1)}, X_{0\ldots (t-1)})\)</span> depend only on information from the past. When optimizing over <span class="math notranslate nohighlight">\(\Delta_\mathcal{C},\)</span> the information gap <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T}\vert X_{0\ldots T})\)</span> might not vanish. Loosely, the gap represents <em>the cost of present separation</em> and <em>the cost of future ignorance</em>. Indeed, if <span class="math notranslate nohighlight">\(Z_t\)</span> and <span class="math notranslate nohighlight">\(X_t\)</span> are not conditionally independent given their past, then either their states are entangled (e.g. <span class="math notranslate nohighlight">\(X_t\)</span> in one state bars <span class="math notranslate nohighlight">\(Z_t\)</span> from another state) or their dependence is coming from knowledge of the future. Since the gap vanishes when we optimize over distributions that allow such kinds of dependence, entanglements and future knowledge must be furnishing information for closing this gap.</p>
</div>
<div class="section" id="how-do-we-perform-relative-inference-with-limited-memory">
<h2>How do we perform relative inference with limited memory?<a class="headerlink" href="#how-do-we-perform-relative-inference-with-limited-memory" title="Permalink to this headline">#</a></h2>
<p>Suppose now that computationally, both the discriminative model and the generative model have limited memory. More precisely, the models cannot store the full histories <span class="math notranslate nohighlight">\(Z_{0\ldots t}, X_{0\ldots t}\)</span> but they can recall the most recent states <span class="math notranslate nohighlight">\(Z_t, X_t.\)</span> In other words, the distributions satisfy the Markov property. Hence, <span class="math notranslate nohighlight">\(Q(Z_{0\ldots T}\vert X_{0\ldots T})\)</span> has a factorization</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl} Q(Z_{0\ldots T}\vert X_{0\ldots T}) &amp; = Q(Z_0) \\ &amp; \\ &amp; \quad Q(Z_1 \vert Z_0,X_0) \cdots \\ &amp; \\ &amp; \quad Q(Z_T \vert Z_{T-1}, X_{T-1}). \end{array}\end{split}\]</div>
<p>Let <span class="math notranslate nohighlight">\(\Delta_\mathcal{M} \subset \Delta_\mathcal{C}\)</span> be the subspace of distributions with this factorization property.</p>
<p>Compared to minimizing the objective <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T},X_{0\ldots T})\)</span> for <span class="math notranslate nohighlight">\(Q\)</span> over the larger space <span class="math notranslate nohighlight">\(\Delta_\mathcal{C},\)</span> we will incur an additional increase in the information gap <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T}\vert  X_{0\ldots T})\)</span> due to the Markov constraint. We can think of this increase as the cost of <em>limited memory</em>.</p>
<p>Of course, the recent state <span class="math notranslate nohighlight">\(Z_t\)</span> could be used to store copies of older states <span class="math notranslate nohighlight">\(Z_{t-1}, Z_{t-2}, \ldots\)</span> but because the dimension of <span class="math notranslate nohighlight">\(Z_t\)</span> is finite, only a limited number of those states can be stored. A smarter way is to compress those states, or to only store pertinent information about those states.</p>
</div>
<div class="section" id="how-do-we-perform-relative-inference-with-limited-sensing">
<h2>How do we perform relative inference with limited sensing?<a class="headerlink" href="#how-do-we-perform-relative-inference-with-limited-sensing" title="Permalink to this headline">#</a></h2>
<p>For our mathematical analysis, we find it semantically convenient to assume that the process <span class="math notranslate nohighlight">\(X_{0\ldots T}\)</span> represents the history of <em>every particle in the universe</em> and that it is a Markov process. Some subprocesses of <span class="math notranslate nohighlight">\(X_{0\ldots T}\)</span> will be observed during training, while other subprocesses may remain hidden.</p>
<p>Observability will be determined by structures in the discriminative model <span class="math notranslate nohighlight">\(\{Q(Z\vert X)\}\)</span> and generative model <span class="math notranslate nohighlight">\(\{P(Z, X)\}.\)</span> If a subprocess of <span class="math notranslate nohighlight">\(X_{0\ldots T}\)</span> is hidden, then the memory <span class="math notranslate nohighlight">\(Z_{0\ldots T}\)</span> will be independent of the subprocess in the discriminative model. In the generative model, we can assign a trivial distribution (e.g. assigning uniform distributions or assigning probability one to some fixed state) to the hidden subprocess.</p>
<p>Such constraints on the discriminative model and generative model <span class="xref myst">could</span> cause the information gap <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T}\vert  X_{0\ldots T})\)</span> to increase yet again. We can think of this increase as the cost of <em>limited sensing</em>.</p>
<p>The reason we say that this Markov assumption is <em>semantically convenient</em> is as follows. We could alternatively model the universe as a joint process <span class="math notranslate nohighlight">\(X_{0\ldots T}, U_{0\ldots T}\)</span> where <span class="math notranslate nohighlight">\(X_{0\ldots T}\)</span> is observed and <span class="math notranslate nohighlight">\(U_{0\ldots T}\)</span> is hidden. However, the mathematical analysis becomes notationally complicated because of the need to write down both processes. It is easier to subsume the distinction between observed and hidden under assumptions for the discriminative model and generative model.</p>
<p>Under this Markov assumption and under mild regularity conditions, the time-averaged relative information will be equal to the relative information rate.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl}  V(Q,P) &amp;= \displaystyle \lim_{T \rightarrow \infty} \frac{1}{T} I_{Q \Vert P}(Z_{0\ldots T},X_{0\ldots T}) \\ &amp; \\ &amp; \displaystyle = \lim_{T\rightarrow \infty} \frac{d}{dT}I_{Q \Vert P}(Z_{0\ldots T}, X_{0\ldots T}) \end{array}\end{split}\]</div>
<p>The discrete time analogue of the relative information rate under this Markov setting is the asymptotic conditional relative information</p>
<div class="math notranslate nohighlight">
\[\lim_{n\rightarrow \infty} I_{Q \Vert P}(Z_{n+1},X_{n+1}\vert Z_n, X_n).\]</div>
<p>Our goal is therefore to train the model by minimizing the relative information rate or conditional relative information over Markov models <span class="math notranslate nohighlight">\(\{Q \}\)</span> and <span class="math notranslate nohighlight">\(\{ P_\theta \}\)</span> using methods from relative inference.</p>
<p>Biological spiking networks need to work with the constraints of not knowing the future and having limited memory and sensing. For the remainder of this series, we will also work with these constraints.</p>
</div>
<div class="section" id="remark-cost-of-limited-sensing">
<h2>Remark: Cost of limited sensing<a class="headerlink" href="#remark-cost-of-limited-sensing" title="Permalink to this headline">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(V_t\)</span> and <span class="math notranslate nohighlight">\(U_t\)</span> be the observed and hidden components of each <span class="math notranslate nohighlight">\(X_t.\)</span> Suppose the generative model <span class="math notranslate nohighlight">\(P(Z_{0\ldots T},X_{0\ldots T})\)</span> assigns probability one to some fixed path of <span class="math notranslate nohighlight">\(\{U_t\}.\)</span></p>
<p>In the decomposition</p>
<div class="math notranslate nohighlight">
\[I_{Q\Vert P}(Z_{0\ldots T},X_{0\ldots T}) = I_{Q\Vert P}(Z_{0\ldots T}\vert  X_{0\ldots T}) + I_{Q_*\Vert P}(X_{0\ldots T})\]</div>
<p>the above trivial assignment of probability will cause <span class="math notranslate nohighlight">\(I_{Q_*\Vert P}(X_{0\ldots T})\)</span> to increase (unless the corresponding true distribution is also trivial).</p>
<p>As for the gap <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T}\vert  X_{0\ldots T}),\)</span> we first note that the variables <span class="math notranslate nohighlight">\(U_t\)</span> cannot provide us with any information about the states <span class="math notranslate nohighlight">\(Z_t\)</span> under <span class="math notranslate nohighlight">\(P,\)</span> so</p>
<div class="math notranslate nohighlight">
\[P(Z_{0\ldots T} \vert V_{0\ldots T}, U_{0\ldots T}) = P(Z_{0\ldots T} \vert V_{0\ldots T}).\]</div>
<p>When <span class="math notranslate nohighlight">\(P\)</span> is fixed, the gap <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z_{0\ldots T}\vert  X_{0\ldots T})\)</span> is minimized when <span class="math notranslate nohighlight">\(Q(Z_{0\ldots T}\vert  X_{0\ldots T})\)</span> is as close to <span class="math notranslate nohighlight">\(P(Z_{0\ldots T} \vert X_{0\ldots T}) = P(Z_{0\ldots T} \vert V_{0\ldots T})\)</span> as possible. Therefore, restricting <span class="math notranslate nohighlight">\(Z_{0\ldots T}\)</span> to depend only on the observables <span class="math notranslate nohighlight">\(V_{0\ldots T}\)</span> under <span class="math notranslate nohighlight">\(Q\)</span> as opposed to all of <span class="math notranslate nohighlight">\(X_{0\ldots T}\)</span> will not cause the information gap to increase. The gap will increase however if <span class="math notranslate nohighlight">\(Q\)</span> is forced to infer <span class="math notranslate nohighlight">\(Z_{0\ldots T}\)</span> from a strict subset of $<span class="math notranslate nohighlight">\(V_{0\ldots T}.\)</span></p>
</div>
</div>

<div class="section">
    

<div class="section">
  <span style="float: left">
     
    <a href="../2021-03-21-process-learning-with-relative-information/">
      <i class="fa fa-arrow-circle-left"></i> Process learning with relative information
    </a>
    
  </span>
  <span>&nbsp;</span>
  <span style="float: right">
     
    <a href="../2021-03-23-biased-stochastic-approximation-with-mutable-processes/">
      Biased stochastic approximation with mutable processes <i
        class="fa fa-arrow-circle-right"
      ></i
      >
    </a>
    
  </span>
</div>
  
</div>

              </article>
              
<p style="margin-bottom:5em;"></p>
<!-- Add a comment box underneath the page's content -->
<script src="https://giscus.app/client.js"
        data-repo="shaoweilin/shaoweilin.github.io"
        data-repo-id="R_kgDOHM5tAA"
        data-category="Blog comments"
        data-category-id="DIC_kwDOHM5tAM4COqgI"
        data-mapping="pathname"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>


              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2022, Shaowei Lin.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>