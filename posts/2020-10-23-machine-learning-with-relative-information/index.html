

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta property="og:title" content="Machine learning with relative information" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://shaoweilin.github.io/posts/2020-10-23-machine-learning-with-relative-information/" />
<meta property="og:site_name" content="Types from Spikes" />
<meta property="og:description" content="We will reframe some common machine learning paradigms, such as maximum likelihood, stochastic gradients, stochastic approximation and variational inference, in terms of relative information. This ..." />
<meta property="og:image" content="https://shaoweilin.github.io/_static/profile.jpg" />
<meta property="og:image:alt" content="Types from Spikes" />
<meta name="description" content="We will reframe some common machine learning paradigms, such as maximum likelihood, stochastic gradients, stochastic approximation and variational inference, in terms of relative information. This ..." />

    <title>Machine learning with relative information &#8212; Types from Spikes  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'posts/2020-10-23-machine-learning-with-relative-information';</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about/" />
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" /> 
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/> 
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../blog/atom.xml"
  title="Types from Spikes"
/>
 
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this site..."
         aria-label="Search this site..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../">
  
  
  
  
  
    <p class="title logo__title">Types from Spikes</p>
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../about/">
                        About
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../blog/">
                        Blog
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<form class="bd-search d-flex align-items-center"
      action="../../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this site..."
         aria-label="Search this site..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/shaoweilin/" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../about/">
                        About
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../blog/">
                        Blog
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<form class="bd-search d-flex align-items-center"
      action="../../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this site..."
         aria-label="Search this site..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/shaoweilin/" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">  
<h2>
   <i class="fa fa-calendar"></i>
  23 October 2020 
</h2>

<ul>
        
</ul>
</div>
        <div class="sidebar-primary-item">
<h3>
  <a href="../../blog/">Recent Posts</a>
</h3>
<ul>
   
  <li>
    <a href="../2024-10-16-singular-learning-relative-information-and-the-dual-numbers/"
      >16 October - Singular learning, relative information and the dual numbers</a
    >
  </li>
  
  <li>
    <a href="../2024-09-24-safety-by-shared-synthesis/"
      >24 September - Safety by shared synthesis</a
    >
  </li>
  
  <li>
    <a href="../2024-05-22-formal-ai-assisted-code-specification-and-synthesis-concrete-steps-towards-safe-sociotechnical-systems/"
      >22 May - Formal AI-assisted code specification and synthesis: concrete steps towards safe sociotechnical systems</a
    >
  </li>
  
  <li>
    <a href="../2024-05-08-ai-assisted-coding-correct-by-construction-not-by-generation/"
      >08 May - AI-assisted coding: correct by construction, not by generation</a
    >
  </li>
  
  <li>
    <a href="../2024-03-21-prior-work-on-program-synthesis/"
      >21 March - Program Synthesis</a
    >
  </li>
  
</ul>
</div>
        <div class="sidebar-primary-item">
<h3>
  <a href="../../blog/archive/">Archives</a>
</h3>
<ul>
   
  <li>
    <a href="../../blog/2024/">2024 (5)</a>
  </li>
    
  <li>
    <a href="../../blog/2023/">2023 (5)</a>
  </li>
    
  <li>
    <a href="../../blog/2022/">2022 (3)</a>
  </li>
    
  <li>
    <a href="../../blog/2021/">2021 (8)</a>
  </li>
    
  <li>
    <a href="../../blog/2020/">2020 (12)</a>
  </li>
    
  <li>
    <a href="../../blog/2018/">2018 (1)</a>
  </li>
    
  <li>
    <a href="../../blog/2017/">2017 (1)</a>
  </li>
    
  <li>
    <a href="../../blog/2016/">2016 (3)</a>
  </li>
    
  <li>
    <a href="../../blog/2014/">2014 (2)</a>
  </li>
    
  <li>
    <a href="../../blog/2012/">2012 (1)</a>
  </li>
   
</ul>
</div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">Machine learning with relative information</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                   <div class="tex2jax_ignore mathjax_ignore section" id="machine-learning-with-relative-information">
<h1>Machine learning with relative information<a class="headerlink" href="#machine-learning-with-relative-information" title="Permalink to this headline">#</a></h1>
<p>We will reframe some common machine learning paradigms, such as maximum likelihood, stochastic gradients, stochastic approximation and variational inference, in terms of relative information.</p>
<p>This post is a continuation from our <a class="reference internal" href="../2020-08-28-motivic-information-path-integrals-and-spiking-networks/"><span class="doc std std-doc">series</span></a> on spiking networks, path integrals and motivic information.</p>
<div class="section" id="what-is-a-statistical-model">
<h2>What is a statistical model?<a class="headerlink" href="#what-is-a-statistical-model" title="Permalink to this headline">#</a></h2>
<p>Given a measurable space <span class="math notranslate nohighlight">\((\Omega, \mathcal{B})\)</span>, let <span class="math notranslate nohighlight">\(\Delta_\Omega\)</span> denote the set of distributions or probability measures on <span class="math notranslate nohighlight">\(\Omega\)</span>. A statistical model is a family <span class="math notranslate nohighlight">\(\{P_\theta\}\)</span> of distributions</p>
<div class="math notranslate nohighlight">
\[P_\theta : \Delta_{\Omega}, \quad \theta\in \Theta\]</div>
<p>parametrized by some space <span class="math notranslate nohighlight">\(\Theta.\)</span></p>
<p>Suppose that the true distribution is some unknown <span class="math notranslate nohighlight">\(Q_* \in \Delta_\Omega.\)</span> The goal of statistical learning is to approximation <span class="math notranslate nohighlight">\(Q_*\)</span> with some model distribution <span class="math notranslate nohighlight">\(P_\theta.\)</span></p>
</div>
<div class="section" id="how-do-we-search-for-the-best-model">
<h2>How do we search for the best model?<a class="headerlink" href="#how-do-we-search-for-the-best-model" title="Permalink to this headline">#</a></h2>
<p>Finding the best model is a common problem not just in machine learning but also in science. We want a model that explains reality well, but also with as few parameters as possible. This latter requirement is called Occam’s Razor. It says that the simplest explanation is most likely the best one.</p>
<p>Finding the simplest explanation is easier said than done. We want to explain the observed data well, but we do not want to overfit the data. At the same time, we also do not want a model that is too overly simplistic, e.g. the uniform distribution. Many modern strategies use a complexity score or regularizer that penalizes the model based on the number of parameters or the dimension of the model. However, the choice of regularizer can seem rather arbitrary at times.</p>
<p>If we have access to the true distribution <span class="math notranslate nohighlight">\(Q_* \in \Delta_\Omega,\)</span> life would be a lot easier. We could try to measure the distance of a model distribution <span class="math notranslate nohighlight">\(P_\theta\)</span> to the true distribution, and attempt to minimize this distance. A natural choice for the distance is the relative information to <span class="math notranslate nohighlight">\(Q_*\)</span> from <span class="math notranslate nohighlight">\(P_\theta\)</span>.</p>
<p>We may also interpret the relative information as the average number of informational bits required to encode data from true distribution using the model, up to some additive constant (see Minimum Description Length, Kolmogorov Complexity and Stochastic Complexity for related concepts). Therefore, minimizing relative information is beneficial from the computational resource management point of view.</p>
<p>However, we do not have access to the true distribution. There are two general strategies for overcoming this obstacle. For simplicity, let us assume there is a probability measure <span class="math notranslate nohighlight">\(M\)</span> such that <span class="math notranslate nohighlight">\(Q_* \ll M\)</span> and <span class="math notranslate nohighlight">\(P_\theta \ll M\)</span>, i.e. both <span class="math notranslate nohighlight">\(Q_*\)</span> and <span class="math notranslate nohighlight">\(P_\theta\)</span> are absolutely continuous with respect to <span class="math notranslate nohighlight">\(M\)</span>. In this case, the densities <span class="math notranslate nohighlight">\(dQ_*/dM\)</span> and <span class="math notranslate nohighlight">\(dP_\theta/dM\)</span> exist.</p>
</div>
<div class="section" id="first-method-maximum-likelihood">
<h2>First method (maximum likelihood)<a class="headerlink" href="#first-method-maximum-likelihood" title="Permalink to this headline">#</a></h2>
<p>We estimate the relative information from the observed data. We may therefore write the relative information as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\displaystyle \begin{array}{rl} I_{Q_* \Vert P_\theta} &amp;=\displaystyle\int \log \frac{dQ_*/dM}{dP_\theta/dM} dQ_* \\ &amp; \\&amp;= \displaystyle\mathbb{E}_{X\sim Q_*} \left[ \log \frac{dQ_*}{dM}(X) \right] - \mathbb{E}_{X\sim Q_*} \left[ \log \frac{dP_\theta}{dM}(X) \right]. \end{array}\end{split}\]</div>
<p>The first term is a constant that does not depend on <span class="math notranslate nohighlight">\(\theta\)</span>, so minimizing the relative information is equivalent to maximizing the second term. The second term may be approximated using the average</p>
<div class="math notranslate nohighlight">
\[\displaystyle \mathbb{E}_{X\sim Q_*} \left[ \log P_\theta(X) \right] = \frac{1}{\left\vert  \mathcal{D}\right\vert }\sum_{x \in \mathcal{D}} \log P_\theta (x)\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> is a finite i.i.d. sample of <span class="math notranslate nohighlight">\(Q_*\)</span>. This approximation is called the <em>log -likelihood</em> of the data set <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. The best model parameter <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> may be estimated by maximizing the log-likelihood. The resulting algorithm is known as the <em>maximum likelihood</em> method.</p>
<p>If the true distribution can be represented by <span class="math notranslate nohighlight">\(Q_* = P_{\theta^*}\)</span> for some parameter <span class="math notranslate nohighlight">\(\theta^*,\)</span> it can be shown that as the sample size grows to infinity, the estimated parameter <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> converges quickly to the true parameter <span class="math notranslate nohighlight">\(\theta^*.\)</span> The asymptotic behavior of the maximum likelihood method is analyzed in <span id="id1">[<a class="reference internal" href="#id58" title="Sumio Watanabe. Algebraic geometry and statistical learning theory. Number 25. Cambridge university press, 2009.">Wat09</a>]</span>.</p>
</div>
<div class="section" id="second-method-stochastic-gradient">
<h2>Second method (stochastic gradient)<a class="headerlink" href="#second-method-stochastic-gradient" title="Permalink to this headline">#</a></h2>
<p>We estimate the <em>gradient</em> of the relative information from observed data. This gradient can be written as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl} \displaystyle \frac{d}{d\theta} I_{Q_* \Vert P_\theta} &amp;= \displaystyle \frac{d}{d\theta} \mathbb{E}_{X\sim Q_*} \left[ \log \frac{dQ_*}{dM}(X) \right] - \frac{d}{d\theta} \mathbb{E}_{X\sim Q_*} \left[ \log \frac{dP_\theta}{dM}(X) \right] \\ &amp; \\&amp;= \displaystyle- \mathbb{E}_{X\sim Q_*} \left[\frac{d}{d\theta} \log \frac{dP_\theta}{dM}(X) \right] \end{array}\end{split}\]</div>
<p>assuming that the expectation and derivative commute by some convergence theorem. This last term can be approximated by the average</p>
<div class="math notranslate nohighlight">
\[\displaystyle \mathbb{E}_{X\sim Q_*} \left[ \frac{d}{d\theta} \log P_\theta(X) \right] = \frac{1}{\left\vert  \mathcal{B}\right\vert }\sum_{x \in \mathcal{B}} \frac{d}{d\theta} \log P_\theta (x)\]</div>
<p>where the <em>batch</em> <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> is a finite i.i.d. sample of <span class="math notranslate nohighlight">\(Q_*\)</span>. This approximation is called the <em>score</em>. We often sample batches of a small fixed size with replacement from a large data set <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> and perform gradient ascent via the batch score. The resulting algorithm is known as the <em>stochastic gradient</em> method.</p>
<p>Batch stochastic gradients have a regularizing effect on the estimator <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> as compared to the gradient of the log-likelihood of the full data set. They ensure that the estimator does not get stuck in a local minima of the log-likelihood function, which corresponds to overfitting of the model to the full data set. The asymptotic behavior of the stochastic gradient method is analyzed in <span id="id2">[<a class="reference internal" href="#id58" title="Sumio Watanabe. Algebraic geometry and statistical learning theory. Number 25. Cambridge university press, 2009.">Wat09</a>]</span>.</p>
</div>
<div class="section" id="how-do-we-apply-stochastic-approximation-via-relative-information">
<h2>How do we apply stochastic approximation via relative information?<a class="headerlink" href="#how-do-we-apply-stochastic-approximation-via-relative-information" title="Permalink to this headline">#</a></h2>
<p>In the stochastic approximation theory of Robbins-Monro, given an increasing function <span class="math notranslate nohighlight">\(f(\theta)\)</span> which cannot be observed directly and has a unique root</p>
<div class="math notranslate nohighlight">
\[f(\theta^*) = 0,\]</div>
<p>the goal is to find this root. We are however given a random variable <span class="math notranslate nohighlight">\(F(\theta)\)</span> that equals <span class="math notranslate nohighlight">\(f(\theta)\)</span> in expectation, i.e.</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[F(\theta)] = f(\theta).\]</div>
<p>The proposed algorithm is to iteratively update</p>
<div class="math notranslate nohighlight">
\[\theta_{n+1} = \theta_n - \eta_n F(\theta_n).\]</div>
<p>where the <span class="math notranslate nohighlight">\(\eta_n\)</span> is a pre-determined sequence of step sizes. Under some weak conditions, the estimates <span class="math notranslate nohighlight">\(\theta_n\)</span> will converge in probability to <span class="math notranslate nohighlight">\(\theta^*.\)</span></p>
<p>We may apply stochastic approximation theory to stochastic optimization problems where the goal is to minimize some</p>
<div class="math notranslate nohighlight">
\[g(\theta) = \mathbb{E} [ G(\theta) ].\]</div>
<p>and the minimizer <span class="math notranslate nohighlight">\(\theta^*\)</span> satisfies <span class="math notranslate nohighlight">\(dg/d\theta(\theta^*) = 0.\)</span> If the expectation and derivative commute, then</p>
<div class="math notranslate nohighlight">
\[\displaystyle \frac{dg}{d\theta}(\theta) = \mathbb{E} \left[ \frac{dG}{d\theta}(\theta) \right]\]</div>
<p>so we may apply stochastic approximation techniques with <span class="math notranslate nohighlight">\(F = dG/d\theta\)</span>.</p>
<p>Applying stochastic optimization to relative information minimization, we may let</p>
<div class="math notranslate nohighlight">
\[\displaystyle G = \log \frac{dP_\theta}{dM}\]</div>
<p>where <span class="math notranslate nohighlight">\(P_\theta\)</span> and <span class="math notranslate nohighlight">\(M\)</span> were defined above for stochastic gradients. As a result, we get a proof that the stochastic gradient algorithm is consistent, i.e. the parameter updates <span class="math notranslate nohighlight">\(\theta_n\)</span> tend to the true parameter <span class="math notranslate nohighlight">\(\theta^*\)</span>. Stronger results may be attained if the model distributions <span class="math notranslate nohighlight">\(P_\theta\)</span> satisfy additional regularity conditions.</p>
</div>
<div class="section" id="how-do-we-frame-variational-inference-in-terms-of-relative-information">
<h2>How do we frame variational inference in terms of relative information?<a class="headerlink" href="#how-do-we-frame-variational-inference-in-terms-of-relative-information" title="Permalink to this headline">#</a></h2>
<p>A latent variable is a random variable for which we have no data. A latent variable model is a statistical model <span class="math notranslate nohighlight">\(\{P_\theta\}\)</span> with some observed variable <span class="math notranslate nohighlight">\(X\)</span> and some latent variable <span class="math notranslate nohighlight">\(Z\)</span>. The marginal distribution of <span class="math notranslate nohighlight">\(X\)</span> is given by the integral</p>
<div class="math notranslate nohighlight">
\[P_\theta(X) = \int P_\theta(X,Z) dZ.\]</div>
<p>For example, we could have a Gaussian mixture model where we have samples from <span class="math notranslate nohighlight">\(k\)</span> Gaussian distributions <span class="math notranslate nohighlight">\(\mathcal{N}_{\mu_1, \Sigma_1}, \ldots, \mathcal{N}_{\mu_k, \Sigma_k}\)</span>, but for each sample <span class="math notranslate nohighlight">\(X\)</span> we do not know the label <span class="math notranslate nohighlight">\(Z \in \{1, \ldots, k\}\)</span> of the Gaussian distribution it was drawn from. The joint distribution of <span class="math notranslate nohighlight">\(X, Z\)</span> is</p>
<div class="math notranslate nohighlight">
\[P_\theta(X,Z) = \alpha_Z \mathcal{N}_{\mu_Z, \Sigma_Z}(X)\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha_1, \ldots, \alpha_k\)</span> are the non-negative mixing weights that sum to one, and</p>
<div class="math notranslate nohighlight">
\[\theta = (\alpha_1, \ldots, \alpha_k, \mu_1, \ldots,\mu_k, \Sigma_1, \ldots, \Sigma_k).\]</div>
<p>The marginal distribution of <span class="math notranslate nohighlight">\(X\)</span> is</p>
<div class="math notranslate nohighlight">
\[P_\theta(X) = \alpha_1 \mathcal{N}_{\mu_1, \Sigma_1}(X) + \cdots + \alpha_k \mathcal{N}_{\mu_k, \Sigma_k}(X).\]</div>
<p>Training latent variable models is notoriously difficult, because the usual maximum likelihood or stochastic gradient methods involve computing the derivative of the logarithm of the above integral which is often tedious.</p>
<p>Instead, we will consider a variational approach. Here, <em>variational</em> means that we will introduce a new <em>functional</em> parameter to the optimization problem, e.g. a parameter which is some function <span class="math notranslate nohighlight">\(Q: S \rightarrow \mathbb{R}\)</span>. If the set <span class="math notranslate nohighlight">\(S\)</span> is infinite, we can think of <span class="math notranslate nohighlight">\(Q\)</span> as an infinite-dimensional vector with entries <span class="math notranslate nohighlight">\(Q(s), s\in S.\)</span></p>
<p>Again, we begin with the goal of minimizing the relative information<br />
<span class="math notranslate nohighlight">\(I_{Q_* \Vert P_\theta}(X)\)</span> to the true distribution <span class="math notranslate nohighlight">\(Q_*(X)\)</span> from the model distribution <span class="math notranslate nohighlight">\(P_\theta(X)\)</span> for the observable <span class="math notranslate nohighlight">\(X\)</span>. We now introduce a variational parameter <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> and let</p>
<div class="math notranslate nohighlight">
\[Q(Z,X) = Q(Z\vert X) Q_*(X).\]</div>
<p>By the chain rule (<span class="xref myst">CR</span>) for relative information,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl} I_{Q\Vert P_\theta}(Z, X) &amp;= I_{Q\Vert P_\theta}(Z\vert X) + I_{Q\Vert P_\theta}(X) \\&amp; \\&amp;= I_{Q\Vert P_\theta}(Z\vert X) + I_{Q_*\Vert P_\theta}(X) .\end{array}\end{split}\]</div>
<p>Therefore,</p>
<div class="math notranslate nohighlight">
\[I_{Q\Vert P_\theta}(Z, X) \geq I_{Q_*\Vert P_\theta}(X) \]</div>
<p>with equality if and only if <span class="math notranslate nohighlight">\(Q(Z\vert X) = P_\theta(Z\vert X).\)</span></p>
<p>Now, if <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> is allowed to be any distribution and if a pair <span class="math notranslate nohighlight">\((\hat{Q}, \hat{\theta})\)</span> minimizes <span class="math notranslate nohighlight">\(I_{Q\Vert P_\theta}(Z, X)\)</span>, then <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> minimizes <span class="math notranslate nohighlight">\(I_{Q_*\Vert P_\theta}(X).\)</span> To see this, let <span class="math notranslate nohighlight">\(\tilde{\theta}\)</span> be a minimizer of <span class="math notranslate nohighlight">\(I_{Q_*\Vert P_\theta}(X)\)</span> and let <span class="math notranslate nohighlight">\(\tilde{Q}(Z\vert X) = p_{\tilde{\theta}}(Z\vert X)\)</span>. Then,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl} I_{Q_*\Vert P_{\hat{\theta}}}(X) &amp;\geq I_{Q_*\Vert P_{\tilde{\theta}}}(X) \\ &amp; \\ &amp;= I_{\tilde{Q} \Vert P_{\tilde{\theta}}}(Z,X) \\ &amp; \\ &amp;\geq I_{\hat{Q} \Vert P_{\hat{\theta}}}(Z,X)\geq I_{Q_*\Vert P_{\hat{\theta}}}(X) \end{array}\end{split}\]</div>
<p>where the first and third inequalities follow from the minimizer assumptions, and the second and fourth equality/inequality follow from the chain rule. Hence, all the inequalities are equalities and <span class="math notranslate nohighlight">\(I_{Q_*\Vert P_{\hat{\theta}}}(X) = I_{Q_*\Vert P_{\tilde{\theta}}}(X)\)</span>, so <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is a minimizer as claimed.</p>
<p>This result suggests a variational strategy for training the latent variable model — introduce a variational parameter <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> and minimize the relative information <span class="math notranslate nohighlight">\(I_{Q\Vert P_\theta}(Z, X)\)</span> over <span class="math notranslate nohighlight">\(Q\)</span> and <span class="math notranslate nohighlight">\(\theta.\)</span></p>
<p>Moreover, we may perform coordinate-wise minimization:</p>
<ol class="arabic simple">
<li><p>holding <span class="math notranslate nohighlight">\(\theta\)</span> constant while minimizing over <span class="math notranslate nohighlight">\(Q\)</span>;</p></li>
<li><p>holding <span class="math notranslate nohighlight">\(Q\)</span> constant while minimizing over <span class="math notranslate nohighlight">\(\theta\)</span>;</p></li>
<li><p>repeat.</p></li>
</ol>
<p>This minimization can be done in an alternating fashion, i.e. fix <span class="math notranslate nohighlight">\(\theta_n\)</span> to find <span class="math notranslate nohighlight">\(Q_{n+1},\)</span> then fix <span class="math notranslate nohighlight">\(Q_{n+1}\)</span> to find <span class="math notranslate nohighlight">\(\theta_{n+1}\)</span>; or it can be done in parallel, i.e. fix <span class="math notranslate nohighlight">\(\theta_n\)</span> to find <span class="math notranslate nohighlight">\(Q_{n+1},\)</span> and fix <span class="math notranslate nohighlight">\(Q_n\)</span> to find <span class="math notranslate nohighlight">\(\theta_{n+1}\)</span> at the same time.</p>
<p>In information geometry <span id="id3">[<a class="reference internal" href="#id48" title="Shun-ichi Amari. Information geometry of the em and em algorithms for neural networks. Neural networks, 8(9):1379–1408, 1995.">Ama95</a>]</span>, the first step is called <em>exponential projection</em> (e-projection) while the second step is called <em>mixture projection</em> (m-projection) (of the log-likelihood, as opposed to minimization of the relative information). This <em>exponential-mixture algorithm</em> (em algorithm) is also related to the <em>expectation-maximization algorithm</em> (EM algorithm) <span id="id4">[<a class="reference internal" href="#id46" title="Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society: Series B (Methodological), 39(1):1–22, 1977.">DLR77</a>]</span>.</p>
<p>Sometimes, the variational parameter <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> is constrained to a space of tractable conditional distributions, or a space of distributions for which the maximization step has an exact solution. In these cases, the optimal value of <span class="math notranslate nohighlight">\(I_{Q\Vert P_\theta}(Z, X)\)</span> may not equal the optimal value of <span class="math notranslate nohighlight">\(I_{Q_* \Vert P_\theta}(X)\)</span>, but it will be an upper bound to the latter. The em algorithm becomes an approximate inference technique, because it minimizes an upper bound and not the desired relative information itself.</p>
<p>From a computational point of view, gaining efficiency in inference at the cost of approximation is a good thing, especially if there are performance guarantees in the form of an upper bound.</p>
</div>
<div class="section" id="how-do-we-interpret-the-variational-parameter-q-z-vert-x">
<h2>How do we interpret the variational parameter <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span>?<a class="headerlink" href="#how-do-we-interpret-the-variational-parameter-q-z-vert-x" title="Permalink to this headline">#</a></h2>
<p>We consider a variety of contexts where the interpretations of <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> are different.</p>
<div class="section" id="context-of-bayesian-statistics">
<h3>Context of Bayesian statistics<a class="headerlink" href="#context-of-bayesian-statistics" title="Permalink to this headline">#</a></h3>
<p>Historically, variational inference was introduced <span id="id5">[<a class="reference internal" href="#id45" title="Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An introduction to variational methods for graphical models. Machine learning, 37(2):183–233, 1999.">JGJS99</a>]</span> to approximate posterior distributions in the context of Bayesian statistics, as an alternative to Markov chain Monte Carlo methods <span id="id6">[<a class="reference internal" href="#id47" title="David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: a review for statisticians. Journal of the American statistical Association, 112(518):859–877, 2017.">BKM17</a>]</span>.</p>
<p>Suppose we have a distribution <span class="math notranslate nohighlight">\(P(X\vert Z)\)</span> and prior <span class="math notranslate nohighlight">\(P(Z)\)</span> for some observed variable <span class="math notranslate nohighlight">\(X\)</span> and some latent variable <span class="math notranslate nohighlight">\(Z.\)</span> The goal is to find the posterior distribution <span class="math notranslate nohighlight">\(P(Z\vert X_*)\)</span> given some data <span class="math notranslate nohighlight">\(X_*.\)</span></p>
<p>Variational inference frames this goal as an optimization problem. Let <span class="math notranslate nohighlight">\(Q_*(X)\)</span> be the atomic distribution with <span class="math notranslate nohighlight">\(Q_*(X_*)=1.\)</span> Let <span class="math notranslate nohighlight">\(\Delta\)</span> be the space of joint distributions on <span class="math notranslate nohighlight">\(Z\)</span> and <span class="math notranslate nohighlight">\(X\)</span> which factors as</p>
<div class="math notranslate nohighlight">
\[Q(Z,X) = Q_*(X) Q(Z\vert X)\]</div>
<p>for some variational parameter <span class="math notranslate nohighlight">\(Q(Z\vert X).\)</span></p>
<p>We claim that the desired posterior <span class="math notranslate nohighlight">\(P(Z\vert X_*)\)</span> is the value of the parameter <span class="math notranslate nohighlight">\(Q(Z\vert X_*)\)</span> which minimizes the conditional relative information <span class="math notranslate nohighlight">\(I_{Q\Vert P}(Z, X)\)</span> as <span class="math notranslate nohighlight">\(Q(Z,X)\)</span> varies over <span class="math notranslate nohighlight">\(\Delta.\)</span> To see this, recall that</p>
<div class="math notranslate nohighlight">
\[\begin{array}{rl} I_{Q\Vert P}(Z, X) = I_{Q\Vert P}(Z\vert X) + I_{Q_*\Vert P}(X) .\end{array}\]</div>
<p>In this sum, the second term is a constant that does not depend on the parameter <span class="math notranslate nohighlight">\(Q(Z\vert X).\)</span> The first term expands to</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{rl}  I_{Q\Vert P}(Z\vert X) &amp;= \displaystyle \int Q(X) \int Q(Z\vert X) \log \frac{Q(Z\vert X)}{P(Z\vert X)} \,dZ \,dX \\ &amp;= \displaystyle \int Q(Z\vert X_*) \log \frac{Q(Z\vert X_*)}{P(Z\vert X_*)} \,dZ \end{array}
\end{split}\]</div>
<p>which is minimized precisely when <span class="math notranslate nohighlight">\(Q(Z\vert X_*) = P(Z\vert X_*).\)</span></p>
<p>Often, we only want to consider distributions <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> which approximate the posterior <span class="math notranslate nohighlight">\(P(Z\vert X)\)</span> and have good computational properties. For example, we may want to store <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> efficiently in a low-dimensional space, or we may want to compute <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> quickly as a composition of simple functions. Through variational inference, we may find this approximation by
optimizing over a smaller space <span class="math notranslate nohighlight">\(\Delta'\)</span> of distributions with the desired computational properties.</p>
<p>In the context of Bayesian statistics, the variational parameter <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> is a computationally-efficient approximation of the model posterior <span class="math notranslate nohighlight">\(P(Z\vert X).\)</span></p>
</div>
<div class="section" id="context-of-statistical-learning">
<h3>Context of statistical learning<a class="headerlink" href="#context-of-statistical-learning" title="Permalink to this headline">#</a></h3>
<p>A second context we may consider is the goal of learning the true distribution <span class="math notranslate nohighlight">\(Q_*(X).\)</span> We solve this problem by proposing two models - a generative model <span class="math notranslate nohighlight">\(\{P(Z,X)\}\)</span> where the marginals <span class="math notranslate nohighlight">\(P(X)\)</span> <em>approximates</em> <span class="math notranslate nohighlight">\(Q_*(X),\)</span> and a discriminative model <span class="math notranslate nohighlight">\(\{Q(Z\vert X)\}\)</span>. From the discriminative model, we define joint distributions <span class="math notranslate nohighlight">\(Q(Z,X) = Q_*(X)Q(Z\vert X)\)</span> which factor through the true distribution <span class="math notranslate nohighlight">\(Q_*(X).\)</span> Note that the marginal <span class="math notranslate nohighlight">\(Q(X)\)</span> <em>equals</em> the true distribution <span class="math notranslate nohighlight">\(Q_*(X)\)</span>. Abusing terminology, we will also call <span class="math notranslate nohighlight">\(\{Q(Z,X)\}\)</span> a <em>discriminative</em> model.</p>
<p>Variational inference is then a joint search over the space of pairs of models. It provides bounds on the distance to <span class="math notranslate nohighlight">\(Q_*(X)\)</span> from <span class="math notranslate nohighlight">\(P(X),\)</span> and it limits the search to computationally efficient discriminative models <span class="math notranslate nohighlight">\(\{Q(Z, X)\}\)</span> and computationally efficient generative models <span class="math notranslate nohighlight">\(\{P(Z,X)\}.\)</span> Variational inference also supplies a distribution <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> for approximate inference of <span class="math notranslate nohighlight">\(Z\)</span> from <span class="math notranslate nohighlight">\(X,\)</span> and a distribution <span class="math notranslate nohighlight">\(P(Z,X)\)</span> for approximate sampling from <span class="math notranslate nohighlight">\(Q_*(X).\)</span></p>
<p>In this context, the variational parameter <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> is therefore interpreted as a disciminative computational model trained on the true distribution.</p>
</div>
<div class="section" id="context-of-optimization">
<h3>Context of optimization<a class="headerlink" href="#context-of-optimization" title="Permalink to this headline">#</a></h3>
<p>A third context we may consider is the goal of optimizing a distance function over some rough low-dimensional landscape. The distance to <span class="math notranslate nohighlight">\(Q_*(X)\)</span> from <span class="math notranslate nohighlight">\(P(X)\)</span> is minimized over the space <span class="math notranslate nohighlight">\(\Lambda\)</span> of pairs of distributions <span class="math notranslate nohighlight">\((Q_*(X),P(X))\)</span> where the first component <span class="math notranslate nohighlight">\(Q_*(X)\)</span> is fixed and the second component <span class="math notranslate nohighlight">\(P(X)\)</span> is the marginalization of some joint distribution <span class="math notranslate nohighlight">\(P(Z,X).\)</span></p>
<p>Variational inference overcomes the roughness of the low-dimensional landscape by lifting the optimization problem to a higher dimensional space where the landscape is smoother. It considers instead the distance to <span class="math notranslate nohighlight">\(Q(Z,X) = Q_*(X)Q(Z\vert X)\)</span> from <span class="math notranslate nohighlight">\(P(Z,X)\)</span> which is minimized over the space <span class="math notranslate nohighlight">\(\Lambda'\)</span> of pairs of distributions <span class="math notranslate nohighlight">\((Q(Z,X),P(Z,X)).\)</span> This space <span class="math notranslate nohighlight">\(\Lambda'\)</span> is of a higher dimension than the original space <span class="math notranslate nohighlight">\(\Lambda\)</span>, and could be infinite-dimensional if <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> is variational.</p>
<p>In this context, instead of projecting <span class="math notranslate nohighlight">\(P(Z,X)\)</span> to the base space of distributions on <span class="math notranslate nohighlight">\(X\)</span> and optimizing the distance between <span class="math notranslate nohighlight">\(Q_*(X)\)</span> and <span class="math notranslate nohighlight">\(P(X)\)</span> in the base space, the disciminative model distribution <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> enables us to lift <span class="math notranslate nohighlight">\(Q_*(X)\)</span> from the base space to a section <span class="math notranslate nohighlight">\(Q(Z,X)\)</span> in the bundle of distributions on <span class="math notranslate nohighlight">\((Z,X)\)</span> so that we can optimize the distance between <span class="math notranslate nohighlight">\(Q(Z,X)\)</span> and <span class="math notranslate nohighlight">\(P(Z,X).\)</span></p>
</div>
</div>
<div class="section" id="why-do-we-need-a-better-name-for-variational-inference">
<h2>Why do we need a better name for variational inference?<a class="headerlink" href="#why-do-we-need-a-better-name-for-variational-inference" title="Permalink to this headline">#</a></h2>
<p>In the statistical learning community, variational inference is sometimes called <em>approximate inference</em> because we are inferring the latent <span class="math notranslate nohighlight">\(Z\)</span> from the observed <span class="math notranslate nohighlight">\(X\)</span> and approximating the Bayes posterior <span class="math notranslate nohighlight">\(P(Z\vert X)\)</span> by solving an variational optimization problem over a space of functions <span class="math notranslate nohighlight">\(Q(Z\vert X).\)</span> For the same reason, it is also called <em>variational Bayes</em>.</p>
<p>In recent work, such as with variational autoencoders, the optimization is performed not over an infinite-dimensional variational space of functions but over a finite-dimensional parametric space of functions. It seems strange to continue using the word <em>variational</em> in describing these techniques.</p>
<p>In other work, the goal has shifted away from inferring the Bayes posterior to inferring model parameters that give the best approximation of the true distribution. Here, it seems strange to continue using the word <em>Bayes</em> in describing these approaches.</p>
<p>Since the goal at hand is still inference and since all of these methods hinge on the use of relative information, specifically on measuring the information loss between the discriminative model and the generative model, I propose that we use the name <em>relative inference</em> instead.</p>
<p>Moreover, instead of calling <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> the <em>variational</em> parameter, I propose calling it and the related joint distribution <span class="math notranslate nohighlight">\(Q(Z,X) = Q(Z\vert X)Q_*(X)\)</span> the <em>discriminative</em> model, to distinguish it from the generative model <span class="math notranslate nohighlight">\(P(Z,X).\)</span></p>
</div>
<div class="section" id="why-should-we-consider-mutable-variables-rather-than-latent-variables">
<h2>Why should we consider mutable variables rather than latent variables?<a class="headerlink" href="#why-should-we-consider-mutable-variables-rather-than-latent-variables" title="Permalink to this headline">#</a></h2>
<p>In this section, we consider models that contain distributions which are only partially known. For example, in the discriminative model of distributions <span class="math notranslate nohighlight">\(Q(Z,X)\)</span> described above, the marginals <span class="math notranslate nohighlight">\(Q(X)\)</span> are all equal to the true distribution <span class="math notranslate nohighlight">\(Q_*(X)\)</span> which is unknown.</p>
<p>Suppose we have a model and random variables <span class="math notranslate nohighlight">\(Z, X\)</span> in the model. We say that <span class="math notranslate nohighlight">\(Z\)</span> is <em>mutable</em> given <span class="math notranslate nohighlight">\(X\)</span> if the conditional distribution <span class="math notranslate nohighlight">\(Q(Z \vert X)\)</span> is known in the model and if there exists at least two distributions where <span class="math notranslate nohighlight">\(Q(Z \vert X)\)</span> is different. This terminology matches with the idea of mutability in data storage systems where a file is mutable if it has at least two different states and it can be changed to any desired state in a reliable way.</p>
<p>We say that the model is <em>mutable</em> if it contains variables <span class="math notranslate nohighlight">\(Z ,X\)</span> such that <span class="math notranslate nohighlight">\(Z\)</span> is mutable given <span class="math notranslate nohighlight">\(X\)</span>. Otherwise, the model is <em>immutable</em>. Likewise, a model for a process <span class="math notranslate nohighlight">\(\{Y_t\}\)</span> is <em>mutable</em> if <span class="math notranslate nohighlight">\(\{Y_t\}\)</span> contains subprocesses <span class="math notranslate nohighlight">\(\{Z_t\}, \{X_t\}\)</span> such that <span class="math notranslate nohighlight">\(\{Z_t\}\)</span> is mutable given <span class="math notranslate nohighlight">\(\{X_t\}.\)</span> When the model is clear from the context, we abuse notation and say that the process itself is mutable.</p>
<p>The starting point in relative inference is a pair of models - the discriminative model <span class="math notranslate nohighlight">\(Q(Z,X)\)</span> and the generative model <span class="math notranslate nohighlight">\(P(Z,X)\)</span> - over variables <span class="math notranslate nohighlight">\(Z, X.\)</span> If the discriminative model is immutable, then relative inference is reduced to the good old-fashioned maximum likelihood method where the goal is to minimize the relative information between the true distribution <span class="math notranslate nohighlight">\(Q_*(X)\)</span> and a generative distribution <span class="math notranslate nohighlight">\(P(X).\)</span></p>
<p>If the discriminative model is mutable, then more interesting methods can be derived. One can think of the mutable variables <span class="math notranslate nohighlight">\(Z\)</span> as stochastic computational units that depend on the given inputs <span class="math notranslate nohighlight">\(X.\)</span> If we ignore learning/training for now, then specifying a mutable model of stochastic discrminative distributions is analogous to specifying a programmable class of deterministic input-driven algorithms. Training the mutable model for a suitable distribution would then be analogous to searching the programmable class for a suitable algorithm.</p>
<p>How then do we make sense of the observable variables and latent variables appearing in traditional applications of relative inference? The strategy for inferring possible distributions for the latent variables is to represent them with variables <span class="math notranslate nohighlight">\(Z\)</span> that are mutable given the observed variables <span class="math notranslate nohighlight">\(X.\)</span> During training, the conditionals <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> are adjusted until the relative information between the discriminative distribution <span class="math notranslate nohighlight">\(Q(Z,X)\)</span> and the generative distribution <span class="math notranslate nohighlight">\(P(Z,X)\)</span> is minimized. Therefore, by <em>using</em> mutable processes, we may <em>uncover</em> latent processes to some extent.</p>
<p>In other applications, such as in modelling spiking neural networks, we represent the universe with a random variable <span class="math notranslate nohighlight">\(X\)</span> which may not be fully observed by the spiking network. In other words, there may be components of <span class="math notranslate nohighlight">\(X\)</span> which are hidden or latent. The only assumption we make about the distribution of <span class="math notranslate nohighlight">\(X\)</span> is that it cannot be changed to a desired distribution in a reliable way.</p>
<p>Our goal for spiking networks is to learn a generative model <span class="math notranslate nohighlight">\(P(Z,X)\)</span> with the help of computational units <span class="math notranslate nohighlight">\(Z\)</span> such that the marginal <span class="math notranslate nohighlight">\(P(X)\)</span> approximates the true distribution. We are not interested in getting guarantees that the variables <span class="math notranslate nohighlight">\(Z\)</span> reflect actual latent variables in the universe <span class="math notranslate nohighlight">\(X\)</span>. To accomplish our goal, we will assume that in the discriminative model <span class="math notranslate nohighlight">\(Q(Z,X),\)</span> the variables <span class="math notranslate nohighlight">\(Z\)</span> are mutable given <span class="math notranslate nohighlight">\(X,\)</span> i.e. the conditionals <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span> are controllable (changeable in a known way).</p>
<p>For the rest of this <a class="reference internal" href="../2020-08-28-motivic-information-path-integrals-and-spiking-networks/"><span class="doc std std-doc">series</span></a>, we will talk more generally of learning <em>by using mutable processes</em>, as opposed to just learning <em>to uncover latent processes</em>.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id7">
<dl class="citation">
<dt class="label" id="id48"><span class="brackets"><a class="fn-backref" href="#id3">Ama95</a></span></dt>
<dd><p>Shun-ichi Amari. Information geometry of the em and em algorithms for neural networks. <em>Neural networks</em>, 8(9):1379–1408, 1995.</p>
</dd>
<dt class="label" id="id47"><span class="brackets"><a class="fn-backref" href="#id6">BKM17</a></span></dt>
<dd><p>David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: a review for statisticians. <em>Journal of the American statistical Association</em>, 112(518):859–877, 2017.</p>
</dd>
<dt class="label" id="id46"><span class="brackets"><a class="fn-backref" href="#id4">DLR77</a></span></dt>
<dd><p>Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from incomplete data via the em algorithm. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, 39(1):1–22, 1977.</p>
</dd>
<dt class="label" id="id45"><span class="brackets"><a class="fn-backref" href="#id5">JGJS99</a></span></dt>
<dd><p>Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An introduction to variational methods for graphical models. <em>Machine learning</em>, 37(2):183–233, 1999.</p>
</dd>
<dt class="label" id="id58"><span class="brackets">Wat09</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>)</span></dt>
<dd><p>Sumio Watanabe. <em>Algebraic geometry and statistical learning theory</em>. Number 25. Cambridge university press, 2009.</p>
</dd>
</dl>
</div>
</div>
</div>

<div class="section">
    

<div class="section">
  <span style="float: left">
     
    <a href="../2020-10-14-path-integrals-and-continuous-time-markov-chains/">
      <i class="fa fa-arrow-circle-left"></i> Path integrals and continuous-time Markov chains
    </a>
    
  </span>
  <span>&nbsp;</span>
  <span style="float: right">
     
    <a href="../2020-12-01-biased-stochastic-approximation/">
      Biased stochastic approximation <i
        class="fa fa-arrow-circle-right"
      ></i
      >
    </a>
    
  </span>
</div>
  
</div>

                </article>
              
<p style="margin-bottom:5em;"></p>
<!-- Add a comment box underneath the page's content -->
<script src="https://giscus.app/client.js"
        data-repo="shaoweilin/shaoweilin.github.io"
        data-repo-id="R_kgDOHM5tAA"
        data-category="Blog comments"
        data-category-id="DIC_kwDOHM5tAM4COqgI"
        data-mapping="pathname"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-statistical-model">What is a statistical model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-search-for-the-best-model">How do we search for the best model?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-method-maximum-likelihood">First method (maximum likelihood)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#second-method-stochastic-gradient">Second method (stochastic gradient)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-apply-stochastic-approximation-via-relative-information">How do we apply stochastic approximation via relative information?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-frame-variational-inference-in-terms-of-relative-information">How do we frame variational inference in terms of relative information?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-interpret-the-variational-parameter-q-z-vert-x">How do we interpret the variational parameter <span class="math notranslate nohighlight">\(Q(Z\vert X)\)</span>?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#context-of-bayesian-statistics">Context of Bayesian statistics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#context-of-statistical-learning">Context of statistical learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#context-of-optimization">Context of optimization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-do-we-need-a-better-name-for-variational-inference">Why do we need a better name for variational inference?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-should-we-consider-mutable-variables-rather-than-latent-variables">Why should we consider mutable variables rather than latent variables?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../../_sources/posts/2020-10-23-machine-learning-with-relative-information.md.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      © Copyright 2022, Shaowei Lin.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.5.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>