
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Posted in 2021 &#8212; Spikes and Types  documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about/" />
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" /> 
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
     
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../blog/atom.xml"
  title="Posted in 2021"
/>
 
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../../">
<p class="title">Spikes and Types</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../about/">
  About
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../">
  Blog
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <form class="bd-search d-flex align-items-center" action="../../search/" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this site..." aria-label="Search this site..." autocomplete="off" >
</form>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/shaoweilin/" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items">
<h3>
  <a href="../">Recent Posts</a>
</h3>
<ul>
   
  <li>
    <a href="../../posts/2022-01-22-information-topos-theory-motivation/"
      >22 January - Information topos theory - motivation</a
    >
  </li>
  
  <li>
    <a href="../../posts/2021-09-09-all-you-need-is-relative-information/"
      >09 September - All you need is relative information</a
    >
  </li>
  
  <li>
    <a href="../../posts/2021-06-05-spiking-neural-networks/"
      >05 June - Spiking neural networks</a
    >
  </li>
  
  <li>
    <a href="../../posts/2021-06-01-convergence-of-biased-stochastic-approximation/"
      >01 June - Convergence of biased stochastic approximation</a
    >
  </li>
  
  <li>
    <a href="../../posts/2021-05-10-path-integrals-and-the-dyson-formula/"
      >10 May - Path integrals and the Dyson formula</a
    >
  </li>
  
</ul>

<h3>
  <a href="../archive/">Archives</a>
</h3>
<ul>
   
  <li>
    <a href="../2022/">2022 (1)</a>
  </li>
    
  <li>
    <a href="#">2021 (8)</a>
  </li>
    
  <li>
    <a href="../2020/">2020 (12)</a>
  </li>
    
  <li>
    <a href="../2018/">2018 (1)</a>
  </li>
    
  <li>
    <a href="../2017/">2017 (1)</a>
  </li>
    
  <li>
    <a href="../2016/">2016 (3)</a>
  </li>
    
  <li>
    <a href="../2014/">2014 (2)</a>
  </li>
    
  <li>
    <a href="../2012/">2012 (1)</a>
  </li>
   
</ul>

              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              

              <div>
                
<div class="section">
  <h1>
     Posted in  2021 
  </h1>
   

  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../posts/2021-09-09-all-you-need-is-relative-information/"
        >All you need is relative information</a
      >
    </h2>

    <ul class="ablog-archive">
      <li>
         <i class="fa fa-calendar"></i> 09 September 2021 
      </li>
            
    </ul>
    <div class="ablog-post-excerpt docutils container">
<p>Relative information (relative entropy, KL divergence) and variational inference are powerful tools for deriving learning algorithms and their asymptotic properties, for both static systems and dynamic systems. The goal of this talk is to motivate a general online stochastic learning algorithm for stochastic processes with latent variables or memory, that provably converges under some regularity conditions. Please visit <a class="reference external" href="https://bit.ly/3kmovql">https://bit.ly/3kmovql</a> for details.</p>
<p>In the first half of the talk, we study static systems, viewing maximum likelihood and Bayesian inference through the lens of relative information. In particular, their generalization errors may be derived by resolving the singularities of relative information. We then frame the two learning algorithms as special cases of variational inference with different computational constraints.</p>
</div>

    <p class="ablog-post-expand"><a href="../../posts/2021-09-09-all-you-need-is-relative-information/"><em>Read more ...</em></a></p>
    <hr />
  </div>
  

  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../posts/2021-06-05-spiking-neural-networks/"
        >Spiking neural networks</a
      >
    </h2>

    <ul class="ablog-archive">
      <li>
         <i class="fa fa-calendar"></i> 05 June 2021 
      </li>
            
    </ul>
    <div class="ablog-post-excerpt docutils container">
<p>In this post, we study a class of spiking network models based on continuous-time <a class="reference external" href="2020-10-14-path-integrals-and-continuous-time-markov-chains/#what-is-a-continuous-time-markov-chain">Markov</a> chains with <a class="reference external" href="2021-03-22-relative-inference-with-mutable-processes/#what-is-a-mutable-process">mutable</a>  variables.</p>
<p>Using a <span class="xref myst">relative inference</span> recipe for online learning, we derive local Hebbian learning rules for the spiking network which are provably convergent to local minima of the relative information objective.</p>
</div>

    <p class="ablog-post-expand"><a href="../../posts/2021-06-05-spiking-neural-networks/"><em>Read more ...</em></a></p>
    <hr />
  </div>
  

  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../posts/2021-06-01-convergence-of-biased-stochastic-approximation/"
        >Convergence of biased stochastic approximation</a
      >
    </h2>

    <ul class="ablog-archive">
      <li>
         <i class="fa fa-calendar"></i> 01 June 2021 
      </li>
            
    </ul>
    <div class="ablog-post-excerpt docutils container">
<p>Using techniques from <span class="xref myst">biased</span> stochastic approximation <span id="id1">[<a class="reference internal" href="../../posts/2021-06-05-spiking-neural-networks/#id38" title="Belhal Karimi, Blazej Miasojedow, Eric Moulines, and Hoi-To Wai. Non-asymptotic analysis of biased stochastic approximation scheme. In Conference on Learning Theory, 1944–1974. PMLR, 2019.">KMMW19</a>]</span>, we prove under some regularity conditions the convergence of the online learning algorithm proposed <span class="xref myst">previously</span> for mutable Markov processes.</p>
<p>Recall that the algorithm is described by the following updates.</p>
</div>

    <p class="ablog-post-expand"><a href="../../posts/2021-06-01-convergence-of-biased-stochastic-approximation/"><em>Read more ...</em></a></p>
    <hr />
  </div>
  

  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../posts/2021-05-10-path-integrals-and-the-dyson-formula/"
        >Path integrals and the Dyson formula</a
      >
    </h2>

    <ul class="ablog-archive">
      <li>
         <i class="fa fa-calendar"></i> 10 May 2021 
      </li>
            
    </ul>
    <div class="ablog-post-excerpt docutils container">
<p>One of the deepest results in quantum field theory, to me, is the Dyson formula <span id="id1">[<a class="reference internal" href="../../posts/2021-05-10-path-integrals-and-the-dyson-formula/#id19" title="nLab. Dyson formula. \url https://ncatlab.org/nlab/show/Dyson+formula. Accessed: 2021.">nLa</a>]</span>. It describes the solution to the differential equation</p>
<p>in terms of the exponential of the path integral of the operator <span class="math notranslate nohighlight">\(A(t)\)</span>,</p>
</div>

    <p class="ablog-post-expand"><a href="../../posts/2021-05-10-path-integrals-and-the-dyson-formula/"><em>Read more ...</em></a></p>
    <hr />
  </div>
  

  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../posts/2021-04-22-proofs-as-programs-challenges-and-strategies-for-program-synthesis/"
        >Proofs as programs - challenges and strategies for program synthesis</a
      >
    </h2>

    <ul class="ablog-archive">
      <li>
         <i class="fa fa-calendar"></i> 22 April 2021 
      </li>
            
    </ul>
    <div class="ablog-post-excerpt docutils container">
<p>The Curry-Howard correspondence between proofs and programs suggests that we can exploit proof assistants for writing software. I will discuss the challenges behind a naïve execution of this idea, and some preliminary strategies for overcoming them. As an example, we will organize higher-order information in knowledge graphs using dependent type theory, and automate the answering of queries using a proof assistant. In another example, we will explore how decentralized proof assistants can enable mathematicians or programmers to work collaboratively on a theorem or application. If time permits, I will outline connections to canonical structures, reflection (ssreflect), transport, unification and universe management.</p>
<p><a class="reference external" href="https://topos.site/topos-colloquium/">Topos Institute Colloquium</a></p>
</div>

    <p class="ablog-post-expand"><a href="../../posts/2021-04-22-proofs-as-programs-challenges-and-strategies-for-program-synthesis/"><em>Read more ...</em></a></p>
    <hr />
  </div>
  

  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../posts/2021-03-23-biased-stochastic-approximation-with-mutable-processes/"
        >Biased stochastic approximation with mutable processes</a
      >
    </h2>

    <ul class="ablog-archive">
      <li>
         <i class="fa fa-calendar"></i> 23 March 2021 
      </li>
            
    </ul>
    <div class="ablog-post-excerpt docutils container">
<p>The goal of this post is to derive a general online learning recipe for training a <a class="reference external" href="2021-03-22-relative-inference-with-mutable-processes/#what-is-a-mutable-process">mutable</a> process <span class="math notranslate nohighlight">\(\{Z_t,X_t\}\)</span> to learn the true distribution <span class="math notranslate nohighlight">\(Q_*(X)\)</span> of a partially-observed Markov process <span class="math notranslate nohighlight">\(\{X_t\}\)</span>. The recipe returns a generative distribution <span class="math notranslate nohighlight">\(P(Z,X)\)</span> whose marginal <span class="math notranslate nohighlight">\(P(X)\)</span> approximates <span class="math notranslate nohighlight">\(Q_*(X).\)</span></p>
<p>The variables <span class="math notranslate nohighlight">\(Z\)</span> of the mutable process are auxiliary variables that assist in inference and computation. During training, the distribution of <span class="math notranslate nohighlight">\(Z\)</span> given <span class="math notranslate nohighlight">\(X\)</span> is controlled by a discriminative model <span class="math notranslate nohighlight">\(\{Q(Z\vert X)\}.\)</span> Our method works in both discrete time and continuous time. We assume in the mutable process that for each time <span class="math notranslate nohighlight">\(t,\)</span> the variables <span class="math notranslate nohighlight">\(Z_t\)</span> and <span class="math notranslate nohighlight">\(X_t\)</span> are conditionally independent of each other given their past.</p>
</div>

    <p class="ablog-post-expand"><a href="../../posts/2021-03-23-biased-stochastic-approximation-with-mutable-processes/"><em>Read more ...</em></a></p>
    <hr />
  </div>
  

  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../posts/2021-03-22-relative-inference-with-mutable-processes/"
        >Relative inference with mutable processes</a
      >
    </h2>

    <ul class="ablog-archive">
      <li>
         <i class="fa fa-calendar"></i> 22 March 2021 
      </li>
            
    </ul>
    <div class="ablog-post-excerpt docutils container">
<p>We introduce a information-theoretic objective, which is a form of relative information between a discriminative model and a generative model, for learning processes using models with <a class="reference external" href="2020-10-23-machine-learning-with-relative-information/#why-should-we-consider-mutable-variables-rather-than-latent-variables">mutable</a> variables. This technique is known as <a class="reference external" href="2020-10-23-machine-learning-with-relative-information/#why-do-we-need-a-better-name-for-variational-inference">relative inference</a> (also called approximate inference, variational inference or variational Bayes). Such a technique is useful, for instance, for learning processes that contain latent variables.</p>
<p>We discuss natural constraints on the discriminative and generative models, and the consequences of these constraints on:</p>
</div>

    <p class="ablog-post-expand"><a href="../../posts/2021-03-22-relative-inference-with-mutable-processes/"><em>Read more ...</em></a></p>
    <hr />
  </div>
  

  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../posts/2021-03-21-process-learning-with-relative-information/"
        >Process learning with relative information</a
      >
    </h2>

    <ul class="ablog-archive">
      <li>
         <i class="fa fa-calendar"></i> 21 March 2021 
      </li>
            
    </ul>
    <div class="ablog-post-excerpt docutils container">
<p>Over the next few posts, we will derive a distributed learning algorithm for spiking neural networks with <a class="reference external" href="2020-10-23-machine-learning-with-relative-information/#why-should-we-consider-mutable-variables-rather-than-latent-variables">mutable</a> variables that minimizes some natural notion of relative information and provably converges over time. We will model these spiking neural networks with stochastic processes: both discrete-time and continuous-time processes, with or without mutable variables.</p>
<p>In this post, we give a general overview of information-theoretic approaches to training stochastic processes, while postponing discussions about issues that arise from mutable variables.</p>
</div>

    <p class="ablog-post-expand"><a href="../../posts/2021-03-21-process-learning-with-relative-information/"><em>Read more ...</em></a></p>
    <hr />
  </div>
   
</div>

              </div>
              
<p style="margin-bottom:2em;"></p>
<!-- Add a comment box underneath the page's content -->
<script src="https://giscus.app/client.js"
        data-repo="shaoweilin/shaoweilin.github.io"
        data-repo-id="R_kgDOHM5tAA"
        data-category="Blog comments"
        data-category-id="DIC_kwDOHM5tAM4COqgI"
        data-mapping="pathname"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>

              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Shaowei Lin.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>